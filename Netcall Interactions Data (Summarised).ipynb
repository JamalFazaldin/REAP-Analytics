{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sqlalchemy import create_engine, text, inspect\n",
    "\n",
    "\n",
    "# Function for getting the name of a DataFrame\n",
    "def get_var_name(var):\n",
    "    try:\n",
    "        for name, value in globals().items():\n",
    "            if value is var:\n",
    "                return name\n",
    "    except Exception as e:\n",
    "        print(f'Error getting variable name: {e}')\n",
    "    return None\n",
    "\n",
    "def validate_data(df, show_counts=True):\n",
    "    try:\n",
    "        df_name = get_var_name(df)\n",
    "        print(f'#########################################################################################################################################################################################\\nDataFrame: {df_name}')\n",
    "        # Snapshot the dataset\n",
    "        display(df)\n",
    "        # Check for unique values\n",
    "        unique_counts = pd.DataFrame(df.nunique())\n",
    "        unique_counts = unique_counts.reset_index().rename(columns={0:'No. of Unique Values', 'index':'Field Name'})\n",
    "        print(\"Unique values per field:\")\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        display(unique_counts)\n",
    "        pd.reset_option('display.max_rows')\n",
    "        # Checking for duplicates\n",
    "        duplicate_count = df.duplicated().sum()\n",
    "        print(\"\\nNumber of duplicate rows:\")\n",
    "        print(duplicate_count,'\\n')\n",
    "        info = df.info(show_counts=show_counts)\n",
    "        display(info)\n",
    "        # Summary stats\n",
    "        print(\"\\nSummary statistics:\")\n",
    "        display(df.describe())\n",
    "        print('End of data validation\\n#########################################################################################################################################################################################\\n')\n",
    "    except Exception as e:\n",
    "        print(f'Error validating data: {e}')\n",
    "\n",
    "def export_to_csv(df, **kwargs):\n",
    "    try:\n",
    "        # Obtaining wanted directory\n",
    "        directory = kwargs.get('directory',r\"C:\\Users\\jf79\\OneDrive - Office Shared Service\\Documents\\H&F Analysis\\Python CSV Repositry\")\n",
    "        \n",
    "        # Obtaining name of DataFrame\n",
    "        df_name = kwargs.get('df_name',get_var_name(df))\n",
    "        if not isinstance(df_name, str) or df_name == '_':\n",
    "                df_name = input('Dataframe not found in global variables. Please enter a name for the DataFrame: ')\n",
    "\n",
    "        file_path = f'{directory}\\\\{df_name}.csv'\n",
    "\n",
    "        print(f'Exproting {df_name} to CSV...\\n@ {file_path}\\n')\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f'Successfully exported {df_name} to CSV')\n",
    "    except Exception as e:\n",
    "        print(f'Error exporting to CSV: {e}')\n",
    "\n",
    "def query_data(schema, data):\n",
    "    try:\n",
    "        # Define the SQL query\n",
    "        query = f'SELECT * FROM [{schema}].[{data}]'\n",
    "        # Load data into DataFrame\n",
    "        df = pd.read_sql(query, engine)\n",
    "        print(f'Successfully imported {data}')\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'Error querying data: {e}')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def read_directory():\n",
    "    directory = os.getcwd()\n",
    "    files = os.listdir(os.getcwd())\n",
    "    print(f\"Your Current Directory is: {directory}\")\n",
    "    print(\"Files in: %s\" % (files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database credentials\n",
    "db_host = 'LBHHLWSQL0001.lbhf.gov.uk'\n",
    "db_port = '1433'\n",
    "db_name = 'IA_ODS'\n",
    "\n",
    "# Create the connection string for SQL Server using pyodbc with Windows Authentication\n",
    "connection_string = f'mssql+pyodbc://@{db_host}:{db_port}/{db_name}?driver=ODBC+Driver+17+for+SQL+Server&Trusted_Connection=yes'\n",
    "\n",
    "# Create the database engine\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_columns = {\n",
    "    'InteractionsKey':'interactionskey',\n",
    "    'ETLTaskID':'etltaskid',\n",
    "    'RowNumber':'rownumber',\n",
    "    'GroupName':'groupname',\n",
    "    'Type':'type',\n",
    "    'Direction':'direction',\n",
    "    'TimeQueued':'timequeued',\n",
    "    'TimeEnded':'timeended',\n",
    "    'Queue':'queue',\n",
    "    'Skill':'skill',\n",
    "    'Agent':'agent',\n",
    "    'Username':'username',\n",
    "    'UserID':'userid',\n",
    "    'CustomerName':'customername',\n",
    "    'CustomerContact':'customercontact',\n",
    "    'QueueWait':'queuewait',\n",
    "    'Duration':'duration',\n",
    "    'TalkTime':'talktime',\n",
    "    'CallHoldDuration':'callholdduration',\n",
    "    'WrapUpDuration':'wrapupduration',\n",
    "    'AgentHandlingTime':'agenthandlingtime',\n",
    "    'Result':'result',\n",
    "    'ActivityCode':'activitycode',\n",
    "    'AssistedBy':'assistedby',\n",
    "    'TransferredTo':'transferredto',\n",
    "    'MediaInteractionId':'interactionid',\n",
    "    'Subject':'subject',\n",
    "    'CaseReference':'casereference',\n",
    "    'Tags':'tags',\n",
    "    'Forwarded':'forwarded',\n",
    "    'IPAddress':'ipaddress',\n",
    "    'FormattedSource':'formattedsource',\n",
    "    'ConversationID':'conversationid',\n",
    "    'ConversationStartTime':'conversationstarttime',\n",
    "    'ConversationEndTime':'conversationendtime',\n",
    "    'ConversationDuration':'conversationduration'\n",
    "}\n",
    "master_columns = {\n",
    "    'Interaction Id':'interactionid',\n",
    "    'Type':'type',\n",
    "    'Direction':'direction',\n",
    "    'Time Queued':'timequeued',\n",
    "    'Time Ended':'timeended',\n",
    "    'Queue':'queue',\n",
    "    'Skill':'skill',\n",
    "    'Agent':'agent',\n",
    "    'Customer Name':'customername',\n",
    "    'Customer Contact':'customercontact',\n",
    "    'Queue Time':'queuetime',\n",
    "    'Duration':'duration',\n",
    "    'Talk Time':'talktime',\n",
    "    'Hold Time':'holdtime',\n",
    "    'Wrap-up Duration':'wrap-upduration',\n",
    "    'Agent Handling Time':'agenthandlingtime',\n",
    "    'Result':'result',\n",
    "    'Activity Code':'activitycode',\n",
    "    'Assisted By':'assistedby',\n",
    "    'Transferred To':'transferredto',\n",
    "    'Subject':'subject',\n",
    "    'Conversation Start Time':'conversationstarttime',\n",
    "    'Conversation End Time':'conversationendtime',\n",
    "    'Conversation Duration':'conversationduration',\n",
    "    'Agent Username':'agentusername',\n",
    "    'Agent ID':'agentid',\n",
    "    'Case Reference':'casereference',\n",
    "    'Forwarded':'forwarded',\n",
    "    'Source':'source',\n",
    "    'Conversation ID':'conversationid',\n",
    "    'IP Address':'ipaddress'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error querying data: (pyodbc.OperationalError) ('08S01', '[08S01] [Microsoft][ODBC Driver 17 for SQL Server]TCP Provider: An established connection was aborted by the software in your host machine.\\r\\n (10053) (SQLGetData); [08S01] [Microsoft][ODBC Driver 17 for SQL Server]Communication link failure (10053)')\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    }
   ],
   "source": [
    "customer_service_data = query_data(schema='Netcall', data='Interactions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Current Directory is: C:\\Users\\jf79\\OneDrive - Office Shared Service\\Sharepoint Links\\BI - Corporate - Interactions Data\n",
      "Files in: ['desktop.ini', 'Interactions Feb 2023 - Apr 2024 (excl Cust Serv)', 'Interactions Jan 2022 - Dec 2022 (excl Cust Serv)', 'Interactions Jan 2024 - Jun 2024 (excl Cust Serv)', 'Interactions Jun 24 - Jan 25 (excl Cust Serv)', 'Interactions_Jan 2023 (LIMITED GROUPS)']\n"
     ]
    }
   ],
   "source": [
    "root_dir = r\"C:\\Users\\jf79\\OneDrive - Office Shared Service\\Sharepoint Links\\BI - Corporate - Interactions Data\"\n",
    "os.chdir(root_dir)\n",
    "\n",
    "read_directory()\n",
    "\n",
    "# Create an empty DataFrame to store the combined data\n",
    "master_data = pd.DataFrame()\n",
    " \n",
    "# Iterate over each folder in the root directory\n",
    "for folder in os.listdir(root_dir):\n",
    "    folder_path = os.path.join(root_dir, folder)\n",
    "    # Ensure it's a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Iterate over each CSV file in the folder\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".csv\"):  # Ensure it's a CSV file\n",
    "                file_path = os.path.join(folder_path, file)\n",
    " \n",
    "                # Read CSV\n",
    "                df = pd.read_csv(file_path)\n",
    " \n",
    "                # Add a new column with the CSV filename\n",
    "                df[\"Source_File\"] = file\n",
    " \n",
    "                # Append to master DataFrame\n",
    "                master_data = pd.concat([master_data, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'GroupName'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m customer_service \u001b[38;5;241m=\u001b[39m customer_service_data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m----> 2\u001b[0m customer_service \u001b[38;5;241m=\u001b[39m customer_service[\u001b[43mcustomer_service\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGroupName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdult_Social_Care\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m customer_service\u001b[38;5;241m.\u001b[39mrename(\n\u001b[0;32m      4\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcustomer_columns,\n\u001b[0;32m      5\u001b[0m     inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m columns_to_drop \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minteractionskey\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124metltaskid\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrownumber\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muserid\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqueuewait\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallholdduration\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwrapupduration\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformattedsource\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     11\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'GroupName'"
     ]
    }
   ],
   "source": [
    "customer_service = customer_service_data.copy()\n",
    "customer_service = customer_service[customer_service['GroupName'] != 'Adult_Social_Care']\n",
    "customer_service.rename(\n",
    "    columns=customer_columns,\n",
    "    inplace=True\n",
    ")\n",
    "columns_to_drop = [\n",
    "    'interactionskey','etltaskid','rownumber',\n",
    "    'username','userid','queuewait','callholdduration',\n",
    "    'wrapupduration','tags','formattedsource'\n",
    "]\n",
    "customer_service.drop(columns=columns_to_drop, inplace=True)\n",
    "col = customer_service.pop('interactionid')\n",
    "customer_service.insert(0, 'interactionid', col)\n",
    "customer_service['groupname'] = customer_service['groupname'].str.replace('Customer_Services','Customer Services')\n",
    "\n",
    "customer_service.sort_values(\n",
    "    ['timequeued'],\n",
    "    ascending=True,\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "drop = customer_service[customer_service['interactionid'].duplicated(keep='first')]\n",
    "customer_service.drop(\n",
    "    drop.index,\n",
    "    inplace=True\n",
    ")\n",
    "customer_service.reset_index(\n",
    "    drop='index',\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "customer_service['timequeued'] = pd.to_datetime(customer_service['timequeued'], format='mixed', dayfirst=True)\n",
    "customer_service['timeended'] = pd.to_datetime(customer_service['timeended'], format='mixed', dayfirst=True)\n",
    "customer_service['Year'] = customer_service['timequeued'].dt.year\n",
    "customer_service['Month'] = customer_service['timequeued'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_data.copy()\n",
    "master_df.rename(\n",
    "    columns=master_columns,\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# Step 1: Split at the first dot (.)\n",
    "master_df[['groupname', 'to_drop']] = master_df['Source_File'].str.split('.', expand=True)\n",
    " \n",
    "# Step 2: Split at the first opening parenthesis (()\n",
    "master_df[['groupname', 'to_drop']] = master_df['groupname'].str.split('(', expand=True)\n",
    " \n",
    "# Step 3: Clean text (remove punctuation & normalize spaces)\n",
    "master_df['groupname'] = master_df['groupname'].apply(lambda text: re.sub(r\"[^\\w\\s]\", \"\", text).strip())\n",
    "master_df['groupname'] = master_df['groupname'].str.replace('Childrens', 'Children')\n",
    "master_df['groupname'] = master_df['groupname'].str.replace('Children', 'Childrens')\n",
    "master_df['groupname'] = master_df['groupname'].str.replace('ICAT6600', 'ICAT 6600')\n",
    "master_df['groupname'] = master_df['groupname'].str.replace('Refugee', 'Refuge')\n",
    "master_df['groupname'] = master_df['groupname'].str.replace('Refuge', 'Refugee')\n",
    "master_df['groupname'] = master_df['groupname'].str.replace('Netcall HMS', 'HMS')\n",
    "master_df['groupname'] = master_df['groupname'].str.replace('HMS', 'Netcall HMS')\n",
    "master_df['groupname'] = master_df['groupname'].str.replace('Recovery Queue', 'Recovery')\n",
    "\n",
    "col = master_df.pop('interactionid')\n",
    "master_df.insert(0, 'interactionid', col)\n",
    "col = master_df.pop('groupname')\n",
    "master_df.insert(1, 'groupname', col)\n",
    "\n",
    "master_df.sort_values(\n",
    "    ['timequeued','agentid'],\n",
    "    ascending=True,\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "master_df.drop(\n",
    "    columns=['Tags','Source_File','to_drop','Group'],\n",
    "    inplace=True\n",
    ")\n",
    "drop = master_df[master_df['interactionid'].duplicated(keep='first')]\n",
    "master_df.drop(\n",
    "    drop.index,\n",
    "    inplace=True\n",
    ")\n",
    "master_df.reset_index(\n",
    "    drop='index',\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "\n",
    "master_df['timequeued'] = pd.to_datetime(master_df['timequeued'], format='mixed', dayfirst=True)\n",
    "master_df['timeended'] = pd.to_datetime(master_df['timeended'], format='mixed', dayfirst=True)\n",
    "master_df['Year'] = master_df['timequeued'].dt.year\n",
    "master_df['Month'] = master_df['timequeued'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = final_df[final_df['type'] == 'Call']\n",
    "\n",
    "check['result'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "final_df = pd.concat([master_df,customer_service])\n",
    "\n",
    "values_to_change = [\n",
    "    'Unknown','Completed','0'\n",
    "]\n",
    "for value in values_to_change:\n",
    "    if value == '0':\n",
    "        final_df['result'] = final_df['result'].str.replace('0','Failed')\n",
    "    else:\n",
    "        final_df['result'] = final_df['result'].str.replace(f'{value}','Other')\n",
    "\n",
    "validate_data(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_interactions = final_df.groupby(['direction','type','Year','Month','groupname','queue']).agg(\n",
    "    number_of_interactions = ('interactionid', 'count')\n",
    ").reset_index()\n",
    "\n",
    "export_to_csv(aggregated_interactions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
