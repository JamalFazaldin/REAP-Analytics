{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sqlalchemy import create_engine, text, inspect\n",
    "\n",
    "# Database credentials\n",
    "db_host = 'LBHHLWSQL0001.lbhf.gov.uk'\n",
    "db_port = '1433'\n",
    "db_name = 'IA_ODS'\n",
    "\n",
    "# Create the connection string for SQL Server using pyodbc with Windows Authentication\n",
    "connection_string = f'mssql+pyodbc://@{db_host}:{db_port}/{db_name}?driver=ODBC+Driver+17+for+SQL+Server&Trusted_Connection=yes'\n",
    "\n",
    "# Create the database engine\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "\n",
    "# Function for getting the name of a DataFrame\n",
    "def get_var_name(var):\n",
    "    try:\n",
    "        for name, value in globals().items():\n",
    "            if value is var:\n",
    "                return name\n",
    "    except Exception as e:\n",
    "        print(f'Error getting variable name: {e}')\n",
    "    return None\n",
    "\n",
    "def validate_data(df, show_counts=True):\n",
    "    try:\n",
    "        df_name = get_var_name(df)\n",
    "        print(f'#########################################################################################################################################################################################\\nDataFrame: {df_name}')\n",
    "        # Snapshot the dataset\n",
    "        display(df)\n",
    "        # Check for unique values\n",
    "        unique_counts = pd.DataFrame(df.nunique())\n",
    "        unique_counts = unique_counts.reset_index().rename(columns={0:'No. of Unique Values', 'index':'Field Name'})\n",
    "        print(\"Unique values per field:\")\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        display(unique_counts)\n",
    "        pd.reset_option('display.max_rows')\n",
    "        # Checking for duplicates\n",
    "        duplicate_count = df.duplicated().sum()\n",
    "        print(\"\\nNumber of duplicate rows:\")\n",
    "        print(duplicate_count,'\\n')\n",
    "        info = df.info(show_counts=show_counts)\n",
    "        display(info)\n",
    "        # Summary stats\n",
    "        print(\"\\nSummary statistics:\")\n",
    "        display(df.describe())\n",
    "        print('End of data validation\\n#########################################################################################################################################################################################\\n')\n",
    "    except Exception as e:\n",
    "        print(f'Error validating data: {e}')\n",
    "\n",
    "def export_to_csv(df, **kwargs):\n",
    "    try:\n",
    "        # Obtaining wanted directory\n",
    "        directory = kwargs.get('directory',r\"C:\\Users\\jf79\\OneDrive - Office Shared Service\\Documents\\H&F Analysis\\Python CSV Repositry\")\n",
    "        \n",
    "        # Obtaining name of DataFrame\n",
    "        df_name = kwargs.get('df_name',get_var_name(df))\n",
    "        if not isinstance(df_name, str) or df_name == '_':\n",
    "                df_name = input('Dataframe not found in global variables. Please enter a name for the DataFrame: ')\n",
    "\n",
    "        file_path = f'{directory}\\\\{df_name}.csv'\n",
    "\n",
    "        print(f'Exproting {df_name} to CSV...\\n@ {file_path}\\n')\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f'Successfully exported {df_name} to CSV')\n",
    "    except Exception as e:\n",
    "        print(f'Error exporting to CSV: {e}')\n",
    "\n",
    "def query_data(schema, data):\n",
    "    try:\n",
    "        # Define the SQL query\n",
    "        query = f'SELECT * FROM [{schema}].[{data}]'\n",
    "        # Load data into DataFrame\n",
    "        df = pd.read_sql(query, engine)\n",
    "        print(f'Successfully imported {data}')\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'Error querying data: {e}')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def read_directory():\n",
    "    directory = os.getcwd()\n",
    "    files = os.listdir(os.getcwd())\n",
    "    print(f\"Your Current Directory is: {directory}\")\n",
    "    print(\"Files in: %s\" % (files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_columns = {\n",
    "    'InteractionsKey':'interactionskey',\n",
    "    'ETLTaskID':'etltaskid',\n",
    "    'RowNumber':'rownumber',\n",
    "    'GroupName':'groupname',\n",
    "    'Type':'type',\n",
    "    'Direction':'direction',\n",
    "    'TimeQueued':'timequeued',\n",
    "    'TimeEnded':'timeended',\n",
    "    'Queue':'queue',\n",
    "    'Skill':'skill',\n",
    "    'Agent':'agent',\n",
    "    'Username':'username',\n",
    "    'UserID':'userid',\n",
    "    'CustomerName':'customername',\n",
    "    'CustomerContact':'customercontact',\n",
    "    'QueueWait':'queuewait',\n",
    "    'Duration':'duration',\n",
    "    'TalkTime':'talktime',\n",
    "    'CallHoldDuration':'callholdduration',\n",
    "    'WrapUpDuration':'wrapupduration',\n",
    "    'AgentHandlingTime':'agenthandlingtime',\n",
    "    'Result':'result',\n",
    "    'ActivityCode':'activitycode',\n",
    "    'AssistedBy':'assistedby',\n",
    "    'TransferredTo':'transferredto',\n",
    "    'MediaInteractionId':'interactionid',\n",
    "    'Subject':'subject',\n",
    "    'CaseReference':'casereference',\n",
    "    'Tags':'tags',\n",
    "    'Forwarded':'forwarded',\n",
    "    'IPAddress':'ipaddress',\n",
    "    'FormattedSource':'formattedsource',\n",
    "    'ConversationID':'conversationid',\n",
    "    'ConversationStartTime':'conversationstarttime',\n",
    "    'ConversationEndTime':'conversationendtime',\n",
    "    'ConversationDuration':'conversationduration'\n",
    "}\n",
    "master_columns = {\n",
    "    'Interaction Id':'interactionid',\n",
    "    'Type':'type',\n",
    "    'Direction':'direction',\n",
    "    'Time Queued':'timequeued',\n",
    "    'Time Ended':'timeended',\n",
    "    'Queue':'queue',\n",
    "    'Skill':'skill',\n",
    "    'Agent':'agent',\n",
    "    'Customer Name':'customername',\n",
    "    'Customer Contact':'customercontact',\n",
    "    'Queue Time':'queuetime',\n",
    "    'Duration':'duration',\n",
    "    'Talk Time':'talktime',\n",
    "    'Hold Time':'holdtime',\n",
    "    'Wrap-up Duration':'wrap-upduration',\n",
    "    'Agent Handling Time':'agenthandlingtime',\n",
    "    'Result':'result',\n",
    "    'Activity Code':'activitycode',\n",
    "    'Assisted By':'assistedby',\n",
    "    'Transferred To':'transferredto',\n",
    "    'Subject':'subject',\n",
    "    'Conversation Start Time':'conversationstarttime',\n",
    "    'Conversation End Time':'conversationendtime',\n",
    "    'Conversation Duration':'conversationduration',\n",
    "    'Agent Username':'agentusername',\n",
    "    'Agent ID':'agentid',\n",
    "    'Case Reference':'casereference',\n",
    "    'Forwarded':'forwarded',\n",
    "    'Source':'source',\n",
    "    'Conversation ID':'conversationid',\n",
    "    'IP Address':'ipaddress'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error querying data: (pyodbc.InterfaceError) ('IM002', '[IM002] [Microsoft][ODBC Driver Manager] Data source name not found and no default driver specified (0) (SQLDriverConnect)')\n",
      "(Background on this error at: https://sqlalche.me/e/20/rvf5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_service_data = query_data(schema='Netcall', data='Interactions')\n",
    "customer_service_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Current Directory is: C:\\Users\\jf79\\OneDrive - Office Shared Service\\Sharepoint Links\\BI - Corporate - Interactions Data\n",
      "Files in: ['desktop.ini', 'Interactions Feb 2023 - Apr 2024 (excl Cust Serv)', 'Interactions Jan 2022 - Dec 2022 (excl Cust Serv)', 'Interactions Jan 2024 - Jun 2024 (excl Cust Serv)', 'Interactions Jun 24 - Jan 25 (excl Cust Serv)', 'Interactions_Jan 2023 (LIMITED GROUPS)']\n"
     ]
    }
   ],
   "source": [
    "root_dir = r\"C:\\Users\\jf79\\OneDrive - Office Shared Service\\Sharepoint Links\\BI - Corporate - Interactions Data\"\n",
    "os.chdir(root_dir)\n",
    "\n",
    "read_directory()\n",
    "\n",
    "# Create an empty DataFrame to store the combined data\n",
    "master_data = pd.DataFrame()\n",
    " \n",
    "# Iterate over each folder in the root directory\n",
    "for folder in os.listdir(root_dir):\n",
    "    folder_path = os.path.join(root_dir, folder)\n",
    "    # Ensure it's a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Iterate over each CSV file in the folder\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".csv\"):  # Ensure it's a CSV file\n",
    "                file_path = os.path.join(folder_path, file)\n",
    " \n",
    "                # Read CSV\n",
    "                df = pd.read_csv(file_path)\n",
    " \n",
    "                # Add a new column with the CSV filename\n",
    "                df[\"Source_File\"] = file\n",
    " \n",
    "                # Append to master DataFrame\n",
    "                master_data = pd.concat([master_data, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'groupname'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jf79\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'groupname'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m customer_service \u001b[38;5;241m=\u001b[39m customer_service_data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      2\u001b[0m customer_service\u001b[38;5;241m.\u001b[39mrename(\n\u001b[0;32m      3\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcustomer_columns,\n\u001b[0;32m      4\u001b[0m     inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      5\u001b[0m )\n\u001b[1;32m----> 6\u001b[0m customer_service \u001b[38;5;241m=\u001b[39m customer_service[\u001b[43mcustomer_service\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgroupname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdult_Social_Care\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m columns_to_drop \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minteractionskey\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124metltaskid\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrownumber\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muserid\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqueuewait\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallholdduration\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwrapupduration\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformattedsource\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     12\u001b[0m ]\n\u001b[0;32m     13\u001b[0m customer_service\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mcolumns_to_drop, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\jf79\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\jf79\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'groupname'"
     ]
    }
   ],
   "source": [
    "customer_service = customer_service_data.copy()\n",
    "customer_service.rename(\n",
    "    columns=customer_columns,\n",
    "    inplace=True\n",
    ")\n",
    "customer_service = customer_service[customer_service['groupname'] != 'Adult_Social_Care']\n",
    "\n",
    "columns_to_drop = [\n",
    "    'interactionskey','etltaskid','rownumber',\n",
    "    'username','userid','queuewait','callholdduration',\n",
    "    'wrapupduration','tags','formattedsource'\n",
    "]\n",
    "customer_service.drop(columns=columns_to_drop, inplace=True)\n",
    "col = customer_service.pop('interactionid')\n",
    "customer_service.insert(0, 'interactionid', col)\n",
    "customer_service['groupname'] = customer_service['groupname'].str.replace('Customer_Services','Customer Services')\n",
    "\n",
    "customer_service.sort_values(\n",
    "    ['timequeued'],\n",
    "    ascending=True,\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "drop = customer_service[customer_service['interactionid'].duplicated(keep='first')]\n",
    "customer_service.drop(\n",
    "    drop.index,\n",
    "    inplace=True\n",
    ")\n",
    "customer_service.reset_index(\n",
    "    drop='index',\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "customer_service['timequeued'] = pd.to_datetime(customer_service['timequeued'], format='mixed', dayfirst=True)\n",
    "customer_service['timeended'] = pd.to_datetime(customer_service['timeended'], format='mixed', dayfirst=True)\n",
    "customer_service['Year'] = customer_service['timequeued'].dt.year\n",
    "customer_service['Month'] = customer_service['timequeued'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_data.copy()\n",
    "master_df.rename(\n",
    "    columns=master_columns,\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# Step 1: Split at the first dot (.)\n",
    "master_df[['groupname', 'to_drop']] = master_df['Source_File'].str.split('.', expand=True)\n",
    " \n",
    "# Step 2: Split at the first opening parenthesis (()\n",
    "master_df[['groupname', 'to_drop']] = master_df['groupname'].str.split('(', expand=True)\n",
    " \n",
    "# Step 3: Clean text (remove punctuation & normalize spaces)\n",
    "master_df['groupname'] = master_df['groupname'].apply(lambda text: re.sub(r\"[^\\w\\s]\", \"\", text).strip())\n",
    "master_df['groupname'] = master_df['groupname'].str.replace('Childrens', 'Children')\n",
    "master_df['groupname'] = master_df['groupname'].str.replace('Children', 'Childrens')\n",
    "master_df['groupname'] = master_df['groupname'].str.replace('ICAT6600', 'ICAT 6600')\n",
    "master_df['groupname'] = master_df['groupname'].str.replace('Refugee', 'Refuge')\n",
    "master_df['groupname'] = master_df['groupname'].str.replace('Refuge', 'Refugee')\n",
    "master_df['groupname'] = master_df['groupname'].str.replace('Netcall HMS', 'HMS')\n",
    "master_df['groupname'] = master_df['groupname'].str.replace('HMS', 'Netcall HMS')\n",
    "master_df['groupname'] = master_df['groupname'].str.replace('Recovery Queue', 'Recovery')\n",
    "\n",
    "col = master_df.pop('interactionid')\n",
    "master_df.insert(0, 'interactionid', col)\n",
    "col = master_df.pop('groupname')\n",
    "master_df.insert(1, 'groupname', col)\n",
    "\n",
    "master_df.sort_values(\n",
    "    ['timequeued','agentid'],\n",
    "    ascending=True,\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "master_df.drop(\n",
    "    columns=['Tags','Source_File','to_drop','Group'],\n",
    "    inplace=True\n",
    ")\n",
    "drop = master_df[master_df['interactionid'].duplicated(keep='first')]\n",
    "master_df.drop(\n",
    "    drop.index,\n",
    "    inplace=True\n",
    ")\n",
    "master_df.reset_index(\n",
    "    drop='index',\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "\n",
    "master_df['timequeued'] = pd.to_datetime(master_df['timequeued'], format='mixed', dayfirst=True)\n",
    "master_df['timeended'] = pd.to_datetime(master_df['timeended'], format='mixed', dayfirst=True)\n",
    "master_df['Year'] = master_df['timequeued'].dt.year\n",
    "master_df['Month'] = master_df['timequeued'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "final_df = pd.concat([master_df,customer_service])\n",
    "\n",
    "values_to_change = [\n",
    "    'Unknown','Completed','0'\n",
    "]\n",
    "for value in values_to_change:\n",
    "    if value == '0':\n",
    "        final_df['result'] = final_df['result'].str.replace('0','Failed')\n",
    "    else:\n",
    "        final_df['result'] = final_df['result'].str.replace(f'{value}','Other')\n",
    "\n",
    "final_df['nullcount'] = final_df.isna().sum(axis=1)\n",
    "final_df.sort_values(by=['interactionid','nullcount'], inplace=True)\n",
    "drop = final_df[final_df['interactionid'].duplicated(keep='first')]\n",
    "final_df.drop(drop.index, inplace=True)\n",
    "final_df.drop(columns='nullcount', inplace=True)\n",
    "\n",
    "validate_data(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_interactions = final_df.groupby(['direction','type','Year','Month','groupname','queue']).agg(\n",
    "    number_of_interactions = ('interactionid', 'count')\n",
    ").reset_index()\n",
    "\n",
    "export_to_csv(aggregated_interactions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
